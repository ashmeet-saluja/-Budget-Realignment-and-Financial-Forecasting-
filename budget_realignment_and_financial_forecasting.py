# -*- coding: utf-8 -*-
"""Budget Realignment and Financial Forecasting.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17y1I9qWQo83ZhTiwIYZYpUcnQNUEFne9
"""

import pandas as pd
import numpy as np

# Set the random seed for reproducibility
np.random.seed(42)

# Define the time range and departments
years = np.arange(2003, 2024)  # 20 years of data
departments = ['Marketing', 'HR', 'Operations', 'R&D', 'Sales', 'IT', 'Legal', 'Finance', 'Admin']

# Generate synthetic data for 20+ years
budget_data = {
    'Year': np.tile(years, len(departments)),
    'Department': np.repeat(departments, len(years)),
    'Budget_Allocation': np.random.randint(300000, 800000, size=len(departments) * len(years)),
    'Actual_Spend': np.random.randint(250000, 850000, size=len(departments) * len(years)),
    'Budget_Adjustment': np.random.choice([0, 5000, 10000, 20000, np.nan], size=len(departments) * len(years)),
}

# Create a DataFrame
budget_df = pd.DataFrame(budget_data)

# Introduce seasonal fluctuations and some random shifts
budget_df['Budget_Allocation'] += np.random.randint(-20000, 20000, size=budget_df.shape[0])
budget_df['Actual_Spend'] += np.random.randint(-10000, 50000, size=budget_df.shape[0])

# Add missing values (10% missing in 'Budget_Allocation', 'Actual_Spend', 'Budget_Adjustment')
for col in ['Budget_Allocation', 'Actual_Spend', 'Budget_Adjustment']:
    missing_indices = np.random.choice(budget_df.index, size=int(budget_df.shape[0] * 0.1), replace=False)
    budget_df.loc[missing_indices, col] = np.nan

# Duplicate records: Copy some rows
budget_df = pd.concat([budget_df, budget_df.sample(n=50, replace=True)]).reset_index(drop=True)

# Standardize Formats: Introduce inconsistent department names
budget_df['Department'] = budget_df['Department'].replace({
    'Sales': 'sales',   # lowercase 'sales'
    'Operations': 'operations ',  # extra space in 'operations '
    'IT': 'Information Technology',  # Full name instead of 'IT'
    'Finance': 'FINANCE',  # Uppercase 'FINANCE'
    'Admin': 'admin'  # lowercase 'admin'
})

# Consolidate Categories: Create inconsistent categories (like "Sales Team")
budget_df['Department'] = budget_df['Department'].replace({
    'sales': 'Sales Team',   # Merging 'sales' with 'Sales Team'
    'operations ': 'Operations',  # Remove the extra space and standardize
})

# Now, for actual spending data with quarterly spend and outliers
spending_data = {
    'Year': np.tile(years, len(departments)),
    'Department': np.repeat(departments, len(years)),
    'Q1_Spend': np.random.randint(80000, 250000, size=len(departments) * len(years)),
    'Q2_Spend': np.random.randint(90000, 250000, size=len(departments) * len(years)),
    'Q3_Spend': np.random.randint(100000, 250000, size=len(departments) * len(years)),
    'Q4_Spend': np.random.randint(110000, 300000, size=len(departments) * len(years)),
}

# Create spending DataFrame
spending_df = pd.DataFrame(spending_data)

# Add outliers for Sales department (e.g., extraordinary spending in specific years)
outlier_indices = spending_df[(spending_df['Department'] == 'Sales Team') & (spending_df['Year'] % 5 == 0)].index
spending_df.loc[outlier_indices, ['Q1_Spend', 'Q2_Spend', 'Q3_Spend', 'Q4_Spend']] = np.random.randint(500000, 1000000, size=(len(outlier_indices), 4))

# Add missing values (5% missing in each quarterly spend)
for col in ['Q1_Spend', 'Q2_Spend', 'Q3_Spend', 'Q4_Spend']:
    missing_indices = np.random.choice(spending_df.index, size=int(spending_df.shape[0] * 0.05), replace=False)
    spending_df.loc[missing_indices, col] = np.nan

# Revenue Data with seasonal fluctuations and missing values
revenue_data = {
    'Year': np.tile(years, len(departments)),
    'Department': np.repeat(departments, len(years)),
    'Revenue': np.random.randint(1000000, 5000000, size=len(departments) * len(years)),
}

revenue_df = pd.DataFrame(revenue_data)

# Add seasonal fluctuation for Revenue (spike in Q4, typical in many businesses)
revenue_df['Revenue'] += np.random.choice([0, 500000, 1000000], size=revenue_df.shape[0], p=[0.8, 0.15, 0.05])

# Inject missing revenue data for certain years
missing_revenue_indices = np.random.choice(revenue_df.index, size=int(revenue_df.shape[0] * 0.1), replace=False)
revenue_df.loc[missing_revenue_indices, 'Revenue'] = np.nan

# External factors: Inflation, GDP Growth, Consumer Confidence
external_factors = {
    'Year': np.tile(years, len(departments)),
    'Department': np.repeat(departments, len(years)),
    'Inflation_Rate': np.random.uniform(0.01, 0.05, len(departments) * len(years)),  # Random inflation rate between 1% and 5%
    'GDP_Growth_Rate': np.random.uniform(0.01, 0.04, len(departments) * len(years)),  # Random GDP growth rate between 1% and 4%
    'Consumer_Confidence_Index': np.random.randint(90, 130, len(departments) * len(years)),  # Consumer confidence index between 90-130
}

external_factors_df = pd.DataFrame(external_factors)

# Add long-term trends for inflation and GDP (slowly increasing inflation and declining GDP)
external_factors_df['Inflation_Rate'] += np.linspace(0, 0.02, len(years)*len(departments))  # Gradual increase in inflation
external_factors_df['GDP_Growth_Rate'] -= np.linspace(0, 0.02, len(years)*len(departments))  # Gradual decline in GDP growth

# Inject missing data for some external factors (5%)
missing_external_data_indices = np.random.choice(external_factors_df.index, size=int(external_factors_df.shape[0] * 0.05), replace=False)
external_factors_df.loc[missing_external_data_indices, ['Inflation_Rate', 'GDP_Growth_Rate', 'Consumer_Confidence_Index']] = np.nan

# Combine all dataframes into a single dataset for export
final_df = budget_df.merge(spending_df, on=['Year', 'Department'], how='outer')
final_df = final_df.merge(revenue_df, on=['Year', 'Department'], how='outer')
final_df = final_df.merge(external_factors_df, on=['Year', 'Department'], how='outer')

# Save to CSV file
final_df.to_csv("financial_data_with_issues.csv", index=False)

print("Dataset with issues (duplicate records, inconsistent formats, missing values) has been saved.")

from google.colab import files
files.download('/content/financial_data_with_issues.csv')

# Load the dataset
import pandas as pd

# Load the CSV file that was generated earlier
df = pd.read_csv("financial_data_with_issues.csv")

# Step 1: Handle Missing Values
# For numerical columns, let's impute missing values with the mean or median
df['Budget_Allocation'].fillna(df['Budget_Allocation'].mean(), inplace=True)
df['Actual_Spend'].fillna(df['Actual_Spend'].median(), inplace=True)
df['Budget_Adjustment'].fillna(df['Budget_Adjustment'].median(), inplace=True)
df['Q1_Spend'].fillna(df['Q1_Spend'].median(), inplace=True)
df['Q2_Spend'].fillna(df['Q2_Spend'].median(), inplace=True)
df['Q3_Spend'].fillna(df['Q3_Spend'].median(), inplace=True)
df['Q4_Spend'].fillna(df['Q4_Spend'].median(), inplace=True)
df['Revenue'].fillna(df['Revenue'].mean(), inplace=True)
df['Inflation_Rate'].fillna(df['Inflation_Rate'].mean(), inplace=True)
df['GDP_Growth_Rate'].fillna(df['GDP_Growth_Rate'].mean(), inplace=True)
df['Consumer_Confidence_Index'].fillna(df['Consumer_Confidence_Index'].mean(), inplace=True)

# Step 2: Remove Duplicate Records
df.drop_duplicates(inplace=True)

# Step 3: Standardize Formats
df['Department'] = df['Department'].str.strip().str.title()  # Capitalize department names
df['Department'] = df['Department'].replace({
    'Sales Team': 'Sales',   # Consolidate 'Sales Team' to 'Sales'
    'Information Technology': 'IT',  # Standardize 'Information Technology' to 'IT'
})

# Step 4: Consolidate Categories
# Merge 'Sales' and 'Sales Team' into one category (already done above)

# Step 5: Handle Outliers (Example for Actual_Spend)
# Remove outliers for Actual_Spend by capping them based on 95th percentile
percentile_95 = df['Actual_Spend'].quantile(0.95)
df['Actual_Spend'] = df['Actual_Spend'].clip(upper=percentile_95)

# Step 6: Feature Engineering
df['Budget_Variance'] = df['Budget_Allocation'] - df['Actual_Spend']
df['Spend_Efficiency'] = df['Actual_Spend'] / df['Budget_Allocation']
df['Yearly_Revenue_Growth'] = df.groupby('Department')['Revenue'].pct_change() * 100  # Percentage change in revenue

# Step 7: Data Type Corrections
df['Year'] = df['Year'].astype(int)
df['Revenue'] = df['Revenue'].astype(float)
df['Inflation_Rate'] = df['Inflation_Rate'].astype(float)
df['GDP_Growth_Rate'] = df['GDP_Growth_Rate'].astype(float)
df['Consumer_Confidence_Index'] = df['Consumer_Confidence_Index'].astype(float)

# Save the cleaned dataset to a new CSV file
df.to_csv("cleaned_financial_data.csv", index=False)

print("Data cleaning process is complete. The cleaned data has been saved.")

from google.colab import files
files.download('/content/cleaned_financial_data.csv')

# Summary statistics for numerical columns
df.describe()

# Check for missing values
df.isnull().sum()

import matplotlib.pyplot as plt
import seaborn as sns

# Set up the style of the plots
sns.set(style="whitegrid")

# Plot the distribution of Budget Allocation
plt.figure(figsize=(10, 6))
sns.histplot(df['Budget_Allocation'], kde=True, color='blue', bins=30)
plt.title("Distribution of Budget Allocation")
plt.show()

# Plot the distribution of Actual Spend
plt.figure(figsize=(10, 6))
sns.histplot(df['Actual_Spend'], kde=True, color='green', bins=30)
plt.title("Distribution of Actual Spend")
plt.show()

# Plot the distribution of Revenue
plt.figure(figsize=(10, 6))
sns.histplot(df['Revenue'], kde=True, color='orange', bins=30)
plt.title("Distribution of Revenue")
plt.show()

# Plot the distribution of Inflation Rate
plt.figure(figsize=(10, 6))
sns.histplot(df['Inflation_Rate'], kde=True, color='purple', bins=30)
plt.title("Distribution of Inflation Rate")
plt.show()

# Plot pairplot to observe relationships between multiple variables
sns.pairplot(df[['Budget_Allocation', 'Actual_Spend', 'Revenue', 'Inflation_Rate', 'GDP_Growth_Rate']])
plt.show()

# Correlation matrix
corr_matrix = df[['Budget_Allocation', 'Actual_Spend', 'Revenue', 'Inflation_Rate', 'GDP_Growth_Rate']].corr()

# Plot the correlation heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title("Correlation Matrix")
plt.show()

# Department-wise spending analysis
plt.figure(figsize=(12, 8))
sns.boxplot(x='Department', y='Actual_Spend', data=df)
plt.xticks(rotation=45)
plt.title("Department-wise Distribution of Actual Spend")
plt.show()

# Grouping by department and plotting the mean budget allocation vs actual spend
dept_summary = df.groupby('Department')[['Budget_Allocation', 'Actual_Spend']].mean()
dept_summary.plot(kind='bar', figsize=(12, 8))
plt.title("Average Budget Allocation vs Actual Spend by Department")
plt.ylabel("Amount")
plt.show()

# Plotting yearly trends for Budget Allocation and Actual Spend
plt.figure(figsize=(12, 6))
df.groupby('Year')[['Budget_Allocation', 'Actual_Spend']].sum().plot(kind='line')
plt.title("Yearly Trends of Budget Allocation and Actual Spend")
plt.ylabel("Amount")
plt.show()

# Yearly Revenue trends
plt.figure(figsize=(12, 6))
df.groupby('Year')['Revenue'].sum().plot(kind='line', color='orange')
plt.title("Yearly Revenue Trends")
plt.ylabel("Revenue")
plt.show()

# Calculate Spend Efficiency
df['Spend_Efficiency'] = df['Actual_Spend'] / df['Budget_Allocation']

# Plot the Spend Efficiency for different departments
plt.figure(figsize=(12, 6))
sns.boxplot(x='Department', y='Spend_Efficiency', data=df)
plt.xticks(rotation=45)
plt.title("Department-wise Spend Efficiency")
plt.show()

# Calculate Budget Variance
df['Budget_Variance'] = df['Budget_Allocation'] - df['Actual_Spend']

# Plot the Budget Variance by year
plt.figure(figsize=(12, 6))
df.groupby('Year')['Budget_Variance'].sum().plot(kind='line', color='red')
plt.title("Yearly Budget Variance")
plt.ylabel("Variance")
plt.show()

from statsmodels.tsa.arima.model import ARIMA

# Let's create a time series of budget allocation by year
budget_series = df.groupby('Year')['Budget_Allocation'].sum()

# Fit ARIMA model
model = ARIMA(budget_series, order=(1, 1, 1))  # ARIMA(p,d,q) parameters (p=1, d=1, q=1)
model_fit = model.fit()

# Forecast the next 5 years
forecast = model_fit.forecast(steps=5)
print(forecast)

# For ARIMA:
revenue_series = df.groupby('Year')['Revenue'].sum()

# Fit ARIMA model for Revenue
model_revenue = ARIMA(revenue_series, order=(1, 1, 1))
model_revenue_fit = model_revenue.fit()

# Forecast Revenue for the next 5 years
forecast_revenue = model_revenue_fit.forecast(steps=5)
print(forecast_revenue)

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from statsmodels.tsa.arima.model import ARIMA
import warnings

warnings.filterwarnings("ignore")

# Ensure 'Year' column is datetime type and set as index
df['Year'] = pd.to_datetime(df['Year'], format='%Y')
df.set_index('Year', inplace=True)

# Aggregate revenue data by year
revenue_series = df['Revenue'].resample('Y').sum()

# Check for missing values
if revenue_series.isnull().sum() > 0:
    revenue_series = revenue_series.fillna(method='ffill')  # Forward fill missing values

# Fit ARIMA model with optimized parameters
model_revenue = ARIMA(revenue_series, order=(1, 1, 1))
model_revenue_fit = model_revenue.fit()

# Forecast the next 5 years
future_years = pd.date_range(start=revenue_series.index[-1], periods=6, freq='Y')[1:]  # Skip the last known year
forecast_revenue = model_revenue_fit.forecast(steps=5)

# Convert forecast results to DataFrame
forecast_df = pd.DataFrame({'Year': future_years, 'Predicted_Revenue': forecast_revenue})

# Print forecast
print(forecast_df)

# Plot the results
plt.figure(figsize=(10, 5))
plt.plot(revenue_series, label="Historical Revenue", marker='o')
plt.plot(forecast_df['Year'], forecast_df['Predicted_Revenue'], label="Forecasted Revenue", marker='o', linestyle='dashed', color='red')
plt.xlabel("Year")
plt.ylabel("Revenue")
plt.legend()
plt.title("Revenue Forecast for Next 5 Years")
plt.show()

!pip install pmdarima
!pip install --upgrade numpy
!pip install --upgrade pmdarima
!pip uninstall -y numpy pmdarima statsmodels
!pip install numpy==1.21.6
!pip install statsmodels
!pip install pmdarima
from google.colab import files
uploaded = files.upload()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Load the cleaned dataset
df = pd.read_csv('cleaned_financial_data.csv')  # Make sure the file is in the correct path

# Ensure 'Year' is the index for time-series forecasting
df = df.sort_values(by='Year')
df.set_index('Year', inplace=True)

# Select only Revenue for analysis
revenue_series = df.groupby('Year')['Revenue'].sum()  # Aggregate revenue by year

# Step 1: Visualize Revenue Trend
plt.figure(figsize=(10, 5))
plt.plot(revenue_series, marker='o', linestyle='-')
plt.title("Historical Revenue Trend")
plt.xlabel("Year")
plt.ylabel("Revenue")
plt.grid()
plt.show()

# Step 2: Check Stationarity using ADF Test
def check_stationarity(series):
    result = adfuller(series)
    print("ADF Statistic:", result[0])
    print("p-value:", result[1])
    if result[1] <= 0.05:
        print("Series is stationary.")
    else:
        print("Series is NOT stationary. Differencing may be required.")

check_stationarity(revenue_series)

# Step 3: Apply Differencing if needed
revenue_diff = revenue_series.diff().dropna()
check_stationarity(revenue_diff)

# Step 4: Plot ACF and PACF to help identify ARIMA parameters
plt.figure(figsize=(10, 5))
plot_acf(revenue_diff, lags=20)
plt.show()

plt.figure(figsize=(10, 5))
plot_pacf(revenue_diff, lags=20)
plt.show()

# Step 5: Fit ARIMA Model (p, d, q) values based on ACF/PACF
# For example, let's assume p=1, d=1, q=1 after analysis
arima_model = sm.tsa.ARIMA(revenue_series, order=(1, 1, 1))
arima_result = arima_model.fit()

# Step 6: Forecast Next 5 Years
forecast_years = 5
forecast_index = np.arange(revenue_series.index[-1] + 1, revenue_series.index[-1] + 1 + forecast_years)
forecast = arima_result.forecast(steps=forecast_years)

# Step 7: Plot the Forecast
plt.figure(figsize=(10, 5))
plt.plot(revenue_series, label="Historical Revenue", marker='o', linestyle='-')
plt.plot(forecast_index, forecast, label="Forecasted Revenue", marker='o', linestyle='dashed', color='red')
plt.title("ARIMA Revenue Forecast")
plt.xlabel("Year")
plt.ylabel("Revenue")
plt.legend()
plt.grid()
plt.show()

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf

# Load the cleaned dataset
df = pd.read_csv('cleaned_financial_data.csv')  # Make sure the file is in the correct path

# Ensure 'Year' is the index for time-series forecasting
df = df.sort_values(by='Year')
df.set_index('Year', inplace=True)

# Select only Revenue for analysis
revenue_series = df.groupby('Year')['Revenue'].sum()  # Aggregate revenue by year

# Step 1: Visualize Revenue Trend
plt.figure(figsize=(10, 5))
plt.plot(revenue_series, marker='o', linestyle='-')
plt.title("Historical Revenue Trend")
plt.xlabel("Year")
plt.ylabel("Revenue")
plt.grid()
plt.show()

# Step 2: Check Stationarity using ADF Test
def check_stationarity(series):
    result = adfuller(series)
    print("ADF Statistic:", result[0])
    print("p-value:", result[1])
    if result[1] <= 0.05:
        print("Series is stationary.")
    else:
        print("Series is NOT stationary. Differencing may be required.")

check_stationarity(revenue_series)

# Step 3: Apply Differencing if needed
# First difference the data (it will lose one point)
revenue_diff = revenue_series.diff().dropna()

# Check if the differenced series is stationary
check_stationarity(revenue_diff)

# Step 4: Plot ACF and PACF on Original Series (Before Differencing)
plt.figure(figsize=(10, 5))
plot_acf(revenue_series, lags=10)  # Reduced lags to 10
plt.show()

plt.figure(figsize=(10, 5))
plot_pacf(revenue_series, lags=10)  # Reduced lags to 10
plt.show()


# Step 5: Fit ARIMA Model (p, d, q) values based on ACF/PACF
# For example, let's assume p=1, d=1, q=1 after analysis
arima_model = sm.tsa.ARIMA(revenue_series, order=(1, 1, 1))
arima_result = arima_model.fit()

# Step 6: Forecast Next 5 Years
forecast_years = 5
forecast_index = np.arange(revenue_series.index[-1] + 1, revenue_series.index[-1] + 1 + forecast_years)
forecast = arima_result.forecast(steps=forecast_years)

# Step 7: Plot the Forecast
plt.figure(figsize=(10, 5))
plt.plot(revenue_series, label="Historical Revenue", marker='o', linestyle='-')
plt.plot(forecast_index, forecast, label="Forecasted Revenue", marker='o', linestyle='dashed', color='red')
plt.title("ARIMA Revenue Forecast")
plt.xlabel("Year")
plt.ylabel("Revenue")
plt.legend()
plt.grid()
plt.show()

from sklearn.linear_model import LinearRegression

# Assuming `df` is your original data and `X` and `y` are already defined
X = df[['Revenue', 'Inflation_Rate', 'GDP_Growth_Rate']]
y = df['Spend_Efficiency']

# Fit the Linear Regression model
model_efficiency = LinearRegression()
model_efficiency.fit(X, y)

# Now, let's predict the next 5 years' values for Revenue, Inflation Rate, and GDP Growth Rate
# We'll use simple forward-looking projections or assume the same values for simplicity

# You could use your forecasting models here (e.g., ARIMA/Prophet) to get future predictions for these variables
future_years = pd.date_range(start='2025', periods=5, freq='Y').year

# For the sake of example, let's assume that Revenue, Inflation, and GDP Growth are projected to be constant over the next 5 years.
# Replace these with your actual forecasts.
future_revenue = [df['Revenue'].mean()] * 5  # Replace with your forecasted revenue
future_inflation = [df['Inflation_Rate'].mean()] * 5  # Replace with your forecasted inflation rate
future_gdp_growth = [df['GDP_Growth_Rate'].mean()] * 5  # Replace with your forecasted GDP growth rate

# Prepare the future_data DataFrame
future_data = pd.DataFrame({
    'Revenue': future_revenue,
    'Inflation_Rate': future_inflation,
    'GDP_Growth_Rate': future_gdp_growth
})

# Predict the future spend efficiency using the regression model
predicted_efficiency = model_efficiency.predict(future_data)

# Now print or analyze the predicted efficiency for the next 5 years
future_years_efficiency = pd.DataFrame({
    'Year': future_years,
    'Predicted_Spend_Efficiency': predicted_efficiency
})

print(future_years_efficiency)